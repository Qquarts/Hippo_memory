"""
===================================================================================
HIPPO_SUB â€” Complete Hippocampal Circuit with Pattern Completion
===================================================================================
ì§€ì€ì´: GNJz | ë°œí–‰: 2025.11.24

Full Hippocampal Pipeline: DG â†’ CA3 (recurrent) â†’ CA1 â†’ Subiculum

ğŸ“ êµ¬í˜„ëœ í•µì‹¬ ìˆ˜ì‹:

1ï¸âƒ£ Hodgkin-Huxley Neuron Dynamics (via v3_event.HHSomaQuick):
   C_m dV/dt = I_ext + I_syn - g_L(V-E_L) - g_NaÂ·mÂ³h(V-E_Na) - g_KÂ·nâ´(V-E_K)
   
   Gating variables:
   dm/dt = Î±_m(1-m) - Î²_mÂ·m
   dh/dt = Î±_h(1-h) - Î²_hÂ·h
   dn/dt = Î±_n(1-n) - Î²_nÂ·n

2ï¸âƒ£ Short-Term Plasticity (STP) & Post-Tetanic Potentiation (PTP):
   On spike:  S â† min(1.0, S + 0.3),    PTP â† min(2.0, PTP + 0.05)
   Decay:     S â† max(0.0, S - 0.01),   PTP â† max(1.0, PTP - 0.001)

3ï¸âƒ£ Global Inhibition (Feedback inhibition):
   I_inhib(t) = -N_active(t-1) Â· g_inhib
   
   where N_active(t-1) = number of neurons that spiked in previous timestep

4ï¸âƒ£ Subiculum Leaky Integrator (Spike-to-Rate decoder):
   dy/dt = -y/Ï„ + w_in Â· spike(t)
   
   Discrete form:
   y(t+dt) = y(t) + dtÂ·(-y/Ï„ + w_inÂ·spike)

5ï¸âƒ£ Winner-Take-All (WTA) Competition:
   Select top-k neurons by voltage V
   Suppress losers: V_loser â† -70 mV

6ï¸âƒ£ Hippocampal Pathways:
   Mossy Fibers:        DG â†’ CA3  (1:1, strong: Q=80.0, "detonator")
   Recurrent:           CA3 âŸ² CA3 (selective: pattern Q=15.0, background Q=3.0)
   Schaffer Collateral: CA3 â†’ CA1 (1:1, strong: Q=25.0)
   Direct:              CA1 â†’ SUB (spike â†’ rate conversion)

7ï¸âƒ£ Pattern Completion:
   Input: Partial Cue (1/N neurons)
   CA3 Recurrent: Amplifies pattern-specific connections
   Output: Complete Pattern (N/N neurons)

8ï¸âƒ£ Network Architecture:
   Learning:  Full Pattern â†’ DG â†’ CA3 (recurrent strengthens) â†’ CA1 â†’ SUB
   Recall:    Partial Cue â†’ DG â†’ CA3 (completes pattern) â†’ CA1 â†’ SUB â†’ Output

===================================================================================
"""

"""
===================================================================================
ğŸ“¦ Dependencies
===================================================================================

This module depends on `v3_event.py` which contains:
  - CONFIG (global Hodgkin-Huxley parameters)
  - HHSomaQuick (fast HH soma)
  - SynapseCore (synaptic event engine with delay queue)

If v3_event.py is not available, please check the project repository
or contact the author for the full package.

===================================================================================
"""

# Qquarts co Present
# ì§€ì€ì´ : GNJz 
# ë°œí–‰ 2025.11.24

import numpy as np
import random
import sys
from pathlib import Path

# âœ… Add parent directory to path for v3_event import
sys.path.insert(0, str(Path(__file__).parent.parent))

# âœ… í•µì‹¬ ì—”ì§„ ì„í¬íŠ¸
from v3_event import CONFIG, HHSomaQuick, SynapseCore

# ======================================================================
# 1. ë‰´ëŸ° í´ë˜ìŠ¤ ì •ì˜ (DG / CA3 / CA1)
# ======================================================================

class DGLightNeuron:
    """
    Dentate Gyrus Neuron â€” Sparse Encoder
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) HH Dynamics (via HHSomaQuick):
       C_m dV/dt = I_ext + I_syn - g_L(V-E_L) - g_NaÂ·mÂ³h(V-E_Na) - g_KÂ·nâ´(V-E_K)
    
    2) High Leak Current (gL = 0.1):
       I_leak = g_LÂ·(V - E_L)
       â†’ ë†’ì€ leak = ì•½í•œ ìê·¹ì€ í•„í„°ë§, ê°•í•œ ìê·¹ë§Œ í†µê³¼
    
    3) STP/PTP:
       On spike:  S â† min(1.0, S + 0.3),    PTP â† min(2.0, PTP + 0.05)
       Decay:     S â† max(0.0, S - 0.01),   PTP â† max(1.0, PTP - 0.001)
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - DGëŠ” "pattern separator" â€” ìœ ì‚¬ ì…ë ¥ì„ êµ¬ë¶„
    - High leak â†’ sparse coding (ì ì€ ìˆ˜ì˜ ë‰´ëŸ°ë§Œ ë°œí™”)
    - Mossy fiber â†’ CA3ë¡œ ê°•ë ¥í•œ "detonator" ì‹ í˜¸ ì „ë‹¬
    """
    
    def __init__(self, name):
        self.name = name
        cfg = CONFIG["HH"].copy()
        cfg["gL"] = 0.1  # ğŸ“ High leak conductance (sparse coding)
        self.soma = HHSomaQuick(cfg)
        self.S, self.PTP = 0.0, 1.0  # ğŸ“ STP/PTP state variables
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
            S (float): STP state
            PTP (float): PTP state
        """
        self.soma.step(dt, I_ext=I_ext)
        spike = self.soma.spiking()
        
        # ğŸ“ STP/PTP update
        if spike:
            self.S = min(1.0, self.S + 0.3)      # ğŸ“ S â† min(1.0, S + 0.3)
            self.PTP = min(2.0, self.PTP + 0.05)  # ğŸ“ PTP â† min(2.0, PTP + 0.05)
        else:
            self.S = max(0.0, self.S - 0.01)      # ğŸ“ S â† max(0.0, S - 0.01)
            self.PTP = max(1.0, self.PTP - 0.001) # ğŸ“ PTP â† max(1.0, PTP - 0.001)
            
        return spike, self.S, self.PTP


class CA3LightNeuron:
    """
    CA3 Neuron â€” Recurrent Attractor Network
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) HH Dynamics (standard gL):
       C_m dV/dt = I_ext + I_syn + I_recurrent - g_L(V-E_L) - ...
    
    2) Recurrent Input:
       I_recurrent = Î£_j Q_ij Â· S_j Â· PTP_j Â· e^(-(t-t_spike)/Ï„)
       
       where j = other CA3 neurons
    
    3) Pattern-Selective Connectivity:
       Q_ij = { 15.0  if i,j âˆˆ same pattern (strong attractor)
              {  3.0  if random background (10% probability)
              {  0.0  otherwise
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - CA3ëŠ” "auto-associative memory" â€” ë¶€ë¶„ ì…ë ¥ìœ¼ë¡œ ì „ì²´ íŒ¨í„´ ë³µì›
    - Recurrent connections â†’ attractor dynamics
    - Pattern-specific strong links â†’ ì„ íƒì  ì¦í­
    """
    
    def __init__(self, name):
        self.name = name
        self.soma = HHSomaQuick(CONFIG["HH"])  # ğŸ“ Standard HH parameters
        self.S, self.PTP = 0.0, 1.0            # ğŸ“ STP/PTP state variables
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
            S (float): STP state
            PTP (float): PTP state
        """
        self.soma.step(dt, I_ext=I_ext)
        spike = self.soma.spiking()
        
        # ğŸ“ STP/PTP update
        if spike:
            self.S = min(1.0, self.S + 0.3)      # ğŸ“ S â† min(1.0, S + 0.3)
            self.PTP = min(2.0, self.PTP + 0.05)  # ğŸ“ PTP â† min(2.0, PTP + 0.05)
        else:
            self.S = max(0.0, self.S - 0.01)      # ğŸ“ S â† max(0.0, S - 0.01)
            self.PTP = max(1.0, self.PTP - 0.001) # ğŸ“ PTP â† max(1.0, PTP - 0.001)
            
        return spike, self.S, self.PTP


class CA1LightNeuron:
    """
    CA1 Neuron â€” Output Filter
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) HH Dynamics with Medium Leak (gL = 0.08):
       C_m dV/dt = I_ext + I_syn - g_L(V-E_L) - ...
    
    2) Schaffer Collateral Input:
       I_syn = Î£_j Q_j Â· S_j Â· PTP_j Â· e^(-(t-t_spike)/Ï„)
       
       where j = CA3 neurons
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - CA1ì€ CA3ì˜ ì¶œë ¥ì„ "ì •ì œ"í•˜ì—¬ í”¼ì§ˆë¡œ ì „ë‹¬
    - Medium leak â†’ ì¤‘ê°„ ì •ë„ì˜ í•„í„°ë§
    - Schaffer collateral â†’ CA3ì˜ "ì™„ì„±ëœ íŒ¨í„´"ì„ ë°›ìŒ
    """
    
    def __init__(self, name):
        self.name = name
        cfg = CONFIG["HH"].copy()
        cfg["gL"] = 0.08  # ğŸ“ Medium leak conductance
        self.soma = HHSomaQuick(cfg)
        self.S, self.PTP = 0.0, 1.0  # ğŸ“ STP/PTP (not used in this model, but kept for consistency)
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
        """
        self.soma.step(dt, I_ext=I_ext)
        return self.soma.spiking()


# ======================================================================
# 1-1. WTA Helper (Winner-Take-All)
# ======================================================================

def apply_wta(neurons, k=5):
    """
    Winner-Take-All (WTA) â€” Sparse Competition
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) ì „ì•• ê¸°ì¤€ ì •ë ¬:
       V_sorted = sort([V_1, V_2, ..., V_N], descending)
    
    2) Top-k ì„ íƒ:
       Winners = {i | V_i âˆˆ top-k}
    
    3) Losers ì–µì œ:
       For i âˆˆ Losers:
         if V_i > -60 mV: V_i â† -70 mV (forced reset)
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - ì–µì œì„± ì¸í„°ë‰´ëŸ° (GABAergic interneurons)ì˜ í”¼ë“œë°± ì–µì œ ëª¨ì‚¬
    - Sparse representation ìœ ì§€
    - ë…¸ì´ì¦ˆ ì–µì œ
    
    Parameters:
        neurons: ë‰´ëŸ° ë¦¬ìŠ¤íŠ¸
        k: ìŠ¹ì ìˆ˜ (default: 5)
    """
    # ğŸ“ ìˆ˜ì‹: V_sorted = sort([V_1, ..., V_N], descending)
    voltages = [(i, n.soma.V) for i, n in enumerate(neurons)]
    voltages.sort(key=lambda x: x[1], reverse=True)
    
    # ğŸ“ ìˆ˜ì‹: Losers = {i | i âˆ‰ top-k}
    losers = [idx for idx, _ in voltages[k:]]
    
    # ğŸ“ ìˆ˜ì‹: V_loser â† -70 mV (forced reset)
    for idx in losers:
        if neurons[idx].soma.V > -60.0:  # Only reset if above threshold
            neurons[idx].soma.V = -70.0
            neurons[idx].soma.spike_flag = False
            neurons[idx].soma.mode = "rest"


# ======================================================================
# 2. Subiculum (Output Integrator)
# ======================================================================

class SubiculumLight:
    """
    Subiculum â€” Spike-to-Rate Decoder (Leaky Integrator)
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    
    ë¯¸ë¶„ ë°©ì •ì‹:
    dy/dt = -y/Ï„ + w_in Â· spike(t)
    
    ì´ì‚°í™” (Euler method):
    y(t+dt) = y(t) + dt Â· (-y/Ï„ + w_in Â· spike)
          = y(t) Â· (1 - dt/Ï„) + dt Â· w_in Â· spike
    
    where:
    - y(t): Activity rate (ì¶œë ¥ ì‹ í˜¸ ê°•ë„)
    - Ï„: Time constant (ì‹œì •ìˆ˜, ì‘ì„ìˆ˜ë¡ ë¹ ë¥¸ ê°ì‡ )
    - w_in: Input weight (ì…ë ¥ ê°€ì¤‘ì¹˜)
    - spike: Binary input (0 or 1)
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - Subiculumì€ í•´ë§ˆì˜ "ì¶œë ¥ ê²Œì´íŠ¸"
    - Spike train â†’ Rate code ë³€í™˜
    - Ï„ = 2.0 ms â†’ ë¹ ë¥¸ ê°ì‡  (transient memory)
    - í”¼ì§ˆë¡œ ì „ë‹¬í•  "ìš”ì•½ëœ í™œì„±ë„" ìƒì„±
    
    Parameters:
        name: ë‰´ëŸ° ì´ë¦„
        tau: ì‹œì •ìˆ˜ (default: 2.0 ms)
    """
    
    def __init__(self, name, tau=2.0):
        self.name = name
        self.y = 0.0       # ğŸ“ Activity rate (ì¶œë ¥ ê°’)
        self.tau = tau     # ğŸ“ Time constant Ï„
        self.w_in = 5.0    # ğŸ“ Input weight w_in

    def step(self, dt, ca1_spike):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        ğŸ“ ìˆ˜ì‹:
        y(t+dt) = y(t) + dt Â· (-y/Ï„ + w_in Â· spike)
        
        Parameters:
            dt: Timestep (ms)
            ca1_spike: CA1 ìŠ¤íŒŒì´í¬ (bool)
        
        Returns:
            y: í˜„ì¬ activity rate
        """
        # ğŸ“ Leaky Integrator: dy/dt = -y/Ï„ + w_in Â· spike
        decay = -self.y / self.tau                    # ğŸ“ -y/Ï„ (leak term)
        inp = self.w_in if ca1_spike else 0.0        # ğŸ“ w_in Â· spike (input term)
        
        dy = decay + inp                              # ğŸ“ dy/dt
        self.y += dy * dt                             # ğŸ“ y(t+dt) = y(t) + dtÂ·dy/dt
        
        return self.y


# ======================================================================
# 3. ì „ì²´ í†µí•© ì‹œë®¬ë ˆì´ì…˜
# ======================================================================

def run_hippo_complete(N=20, dt=0.1):
    """
    Complete Hippocampal Circuit Simulation
    
    ğŸ“ ì „ì²´ Pipeline:
    
    Phase 1 - Learning:
      Input â†’ DG â†’ CA3 (recurrent) â†’ CA1 â†’ Subiculum
      
      ëª©ì : ì „ì²´ íŒ¨í„´ ì €ì¥
      ì…ë ¥: Full pattern (N neurons)
      ê²°ê³¼: CA3 recurrent synapses ê°•í™”
    
    Phase 2 - Reset:
      ëª¨ë“  ë‰´ëŸ° ë° ì‹œëƒ…ìŠ¤ ì´ˆê¸°í™”
      
      ëª©ì : Learningê³¼ Recall ë¶„ë¦¬
    
    Phase 3 - Recall:
      Partial Cue â†’ DG â†’ CA3 (pattern completion) â†’ CA1 â†’ Subiculum â†’ Output
      
      ëª©ì : ë¶€ë¶„ ì…ë ¥ìœ¼ë¡œ ì „ì²´ íŒ¨í„´ ë³µì›
      ì…ë ¥: Partial cue (1/N neurons)
      CA3 ì—­í• : Recurrent connectionsë¡œ íŒ¨í„´ ì™„ì„±
      ì¶œë ¥: Complete pattern (via Subiculum readout)
    
    ğŸ“ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:
    
    1) Global Inhibition (Feedback):
       I_inhib(t) = -N_active(t-1) Â· g_inhib
       
       â†’ ë§ì€ ë‰´ëŸ°ì´ ë°œí™” â†’ ê°•í•œ ì–µì œ â†’ Sparse coding ìœ ì§€
    
    2) Selective Recurrent (CA3):
       Q_ij = { 15.0  if i,j âˆˆ pattern
              {  3.0  if background
       
       â†’ Pattern neuronsë§Œ ê°•í•˜ê²Œ ì—°ê²° â†’ ì„ íƒì  ì¦í­
    
    3) WTA Competition:
       Top-k neurons ìœ ì§€, ë‚˜ë¨¸ì§€ ì–µì œ
       
       â†’ ë…¸ì´ì¦ˆ ì œê±°, sparse representation
    
    4) Subiculum Readout:
       y = Leaky Integrator (CA1 spikes)
       
       â†’ Spike â†’ Rate ë³€í™˜
       â†’ ì„ê³„ê°’(threshold=2.0) ì´ìƒì´ë©´ "í™œì„±"ìœ¼ë¡œ íŒì •
    
    Parameters:
        N: ë‰´ëŸ° ìˆ˜ (default: 20)
        dt: Timestep (default: 0.1 ms)
    """
    
    # ğŸ² Reproducibility
    random.seed(42)
    np.random.seed(42)

    print(f"\nğŸ§  COMPLETE HIPPOCAMPAL CIRCUIT (DG -> CA3 -> CA1 -> SUB)")
    print("=" * 70)

    # --------------------------------------------------------
    # 1. ë‰´ëŸ° ìƒì„±
    # --------------------------------------------------------
    dg_neurons  = [DGLightNeuron(f"DG{i}")  for i in range(N)]
    ca3_neurons = [CA3LightNeuron(f"CA3{i}") for i in range(N)]
    ca1_neurons = [CA1LightNeuron(f"CA1{i}") for i in range(N)]
    sub_neurons = [SubiculumLight(f"SUB{i}") for i in range(N)]

    # --------------------------------------------------------
    # 2. ì—°ê²° êµ¬ì¶•
    # --------------------------------------------------------
    
    # ğŸ“ DG â†’ CA3 (Mossy Fibers, "Detonator")
    # ìƒë¬¼í•™ì : 1:1 ê°•ë ¥í•œ ì—°ê²° (Q_max=80.0)
    mossy_fibers = []
    for i in range(N):
        syn = SynapseCore(pre_neuron=dg_neurons[i].soma, post_neuron=ca3_neurons[i].soma,
                          delay_ms=1.0, Q_max=80.0, tau_ms=2.0)  # ğŸ“ Strong "detonator"
        mossy_fibers.append(syn)

    # ğŸ“ CA3 â†’ CA3 (Recurrent, Selective)
    # Pattern-specific: ê°•í•œ ì—°ê²° (Q=15.0)
    # Background: ì•½í•œ ì—°ê²° (Q=3.0, 10% probability)
    ca3_synapses = []
    targets = [3, 7, 12, 16]  # ğŸ“ Target pattern (4 neurons)
    
    for i in range(N):
        for j in range(N):
            if i == j: continue
            
            # ğŸ“ Pattern-selective connectivity
            is_pattern_link = (i in targets) and (j in targets)
            
            if is_pattern_link:
                # ğŸ“ Strong attractor: Q=15.0 (pattern neurons)
                syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca3_neurons[j].soma,
                                  delay_ms=1.5, Q_max=15.0, tau_ms=3.0)
                ca3_synapses.append((i, j, syn))
                
            elif random.random() < 0.10:
                # ğŸ“ Weak background: Q=3.0 (10% random)
                syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca3_neurons[j].soma,
                                  delay_ms=1.5, Q_max=3.0, tau_ms=3.0)
                ca3_synapses.append((i, j, syn))

    # ğŸ“ CA3 â†’ CA1 (Schaffer Collaterals)
    # ìƒë¬¼í•™ì : ê°•í•œ ì „ë‹¬ (Q=25.0)
    schaffer_collaterals = []
    for i in range(N):
        syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca1_neurons[i].soma,
                          delay_ms=2.0, Q_max=25.0, tau_ms=3.0)  # ğŸ“ Strong transmission
        schaffer_collaterals.append(syn)

    # ğŸ“ CA1 â†’ Subiculum (Direct, 1:1)
    # Subiculumì€ ë‰´ëŸ° ë‚´ë¶€ì—ì„œ ì§ì ‘ CA1 spikeë¥¼ ë°›ìŒ

    print(f"System Ready: {4*N} Neurons, ~{len(ca3_synapses)+2*N} Synapses")

    # --------------------------------------------------------
    # PHASE 1: LEARNING (Target Pattern Encoding)
    # --------------------------------------------------------
    print("\n=== 1. LEARNING (Encoding) ===")
    T_learn = 50.0  # Learning duration (ms)
    steps = int(T_learn / dt)
    
    # ğŸ“ Global Inhibition Parameters
    DG_INHIB = 80.0   # ğŸ“ DG inhibition strength
    CA3_INHIB = 20.0  # ğŸ“ CA3 inhibition strength
    
    dg_last = 0   # ğŸ“ N_active(t-1) for DG
    ca3_last = 0  # ğŸ“ N_active(t-1) for CA3

    for k in range(steps):
        t = k * dt
        
        # ğŸ“ Input: Full pattern (t < 10 ms)
        dg_in = [0.0] * N
        if t < 10.0:
            for idx in targets:
                dg_in[idx] = 200.0  # ğŸ“ Strong input to target neurons
            
        # --------------------------------------------------------
        # DG Layer
        # --------------------------------------------------------
        dg_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_dg = -1.0 * dg_last * DG_INHIB
        
        for i in range(N):
            sp, S, PTP = dg_neurons[i].step(dt, dg_in[i] + I_dg)
            if sp:
                dg_now += 1
                # ğŸ“ Mossy fiber transmission
                mossy_fibers[i].on_pre_spike(t, S, PTP, 100.0, 0.0)
        
        dg_last = dg_now  # ğŸ“ Update N_active(t-1)

        # --------------------------------------------------------
        # Synapse Delivery
        # --------------------------------------------------------
        for syn in mossy_fibers:
            syn.deliver(t)
        for _, _, syn in ca3_synapses:
            syn.deliver(t)

        # --------------------------------------------------------
        # CA3 Layer (Recurrent)
        # --------------------------------------------------------
        ca3_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_ca3 = -1.0 * ca3_last * CA3_INHIB
        
        for i in range(N):
            I_syn = ca3_neurons[i].soma.get_total_synaptic_current()
            sp, S, PTP = ca3_neurons[i].step(dt, I_syn + I_ca3)
            
            if sp:
                ca3_now += 1
                # ğŸ“ Recurrent & Schaffer transmission
                for pre, post, syn in ca3_synapses:
                    if pre == i:
                        syn.on_pre_spike(t, S, PTP, 100.0, 0.0)
                        
                schaffer_collaterals[i].on_pre_spike(t, S, PTP, 100.0, 0.0)
        
        ca3_last = ca3_now  # ğŸ“ Update N_active(t-1)

    print("âœ… Memory Stored.")

    # --------------------------------------------------------
    # PHASE 2: RESET (System Cooldown)
    # --------------------------------------------------------
    print("\n=== 2. RESET (Consolidation) ===")
    
    # ğŸ“ Cooldown: ëª¨ë“  transient dynamics ì†Œë©¸
    for _ in range(500):
        for n in dg_neurons + ca3_neurons + ca1_neurons:
            n.step(dt, 0)
        for s in mossy_fibers + schaffer_collaterals:
            s.deliver(0)
        for _, _, s in ca3_synapses:
            s.deliver(0)
        for sub in sub_neurons:
            sub.step(dt, False)

    # ğŸ“ Force Reset: ëª¨ë“  state variables ì´ˆê¸°í™”
    all_hh = dg_neurons + ca3_neurons + ca1_neurons
    for n in all_hh:
        n.soma.V = -70.0
        n.soma.spike_flag = False
        n.soma.I_syn_total = 0.0
        n.soma.mode = "rest"
        n.soma.active_remaining = 0.0
        
    for s in mossy_fibers + schaffer_collaterals:
        s.spikes = []
        s.I_syn = 0.0
        
    for _, _, s in ca3_synapses:
        s.spikes = []
        s.I_syn = 0.0
    
    print("âœ… System Cleared.")

    # --------------------------------------------------------
    # PHASE 3: RECALL & READOUT (Pattern Completion)
    # --------------------------------------------------------
    print("\n=== 3. RECALL (Retrieval & Readout) ===")
    print(f"Cue: [{targets[0]}] only -> Expected: {targets}")
    
    T_test = 30.0  # Recall duration (ms)
    steps = int(T_test / dt)
    
    # ğŸ“ Recall Inhibition (stronger than learning)
    DG_INHIB_RECALL = 150.0   # ğŸ“ Strong DG inhibition
    CA3_INHIB_RECALL = 60.0   # ğŸ“ Strong CA3 inhibition
    CA1_INHIB_RECALL = 35.0   # ğŸ“ CA1 noise filter

    dg_last = 0
    ca3_last = 0
    
    # ğŸ“ Subiculum output storage
    sub_outputs = np.zeros(N)

    for k in range(steps):
        t = k * dt
        
        # --------------------------------------------------------
        # 1. DG (Input Layer)
        # --------------------------------------------------------
        dg_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_dg = -1.0 * dg_last * DG_INHIB_RECALL
        
        for i in range(N):
            # ğŸ“ Partial Cue: Only first target neuron (t < 10 ms)
            I_in = 200.0 if (i == targets[0] and t < 10.0) else 0.0
            sp, S, PTP = dg_neurons[i].step(dt, I_in + I_dg)
            
            if sp:
                dg_now += 1
                mossy_fibers[i].on_pre_spike(t, S, PTP, 100.0, 0.0)
        
        dg_last = dg_now

        # --------------------------------------------------------
        # 2. Synapse Delivery
        # --------------------------------------------------------
        for syn in mossy_fibers:
            syn.deliver(t)
        for _, _, syn in ca3_synapses:
            syn.deliver(t)
        for syn in schaffer_collaterals:
            syn.deliver(t)

        # --------------------------------------------------------
        # 3. CA3 (Pattern Completion with WTA)
        # --------------------------------------------------------
        ca3_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_ca3 = -1.0 * ca3_last * CA3_INHIB_RECALL
        
        for i in range(N):
            I_syn = ca3_neurons[i].soma.get_total_synaptic_current()
            sp, S, PTP = ca3_neurons[i].step(dt, I_syn + I_ca3)
            
            if sp:
                ca3_now += 1
                # ğŸ“ Recurrent amplification
                for pre, post, syn in ca3_synapses:
                    if pre == i:
                        syn.on_pre_spike(t, S, PTP, 100.0, 0.0)
                        
                schaffer_collaterals[i].on_pre_spike(t, S, PTP, 100.0, 0.0)
        
        ca3_last = ca3_now
        
        # ğŸ“ WTA: Sparse competition (after 2.0 ms)
        if t > 2.0:
            apply_wta(ca3_neurons, k=len(targets))

        # --------------------------------------------------------
        # 4. CA1 (Output Filtering with WTA)
        # --------------------------------------------------------
        I_ca1 = -CA1_INHIB_RECALL  # ğŸ“ Constant inhibition
        
        for i in range(N):
            I_syn = ca1_neurons[i].soma.get_total_synaptic_current()
            sp = ca1_neurons[i].step(dt, I_syn + I_ca1)
            
            # --------------------------------------------------------
            # 5. Subiculum (Spike-to-Rate Integration)
            # --------------------------------------------------------
            # ğŸ“ Leaky Integrator: y(t+dt) = y(t) + dtÂ·(-y/Ï„ + wÂ·spike)
            y = sub_neurons[i].step(dt, sp)
            sub_outputs[i] = max(sub_outputs[i], y)  # ğŸ“ Peak activity
        
        # ğŸ“ WTA: Sparse competition (after 3.0 ms)
        if t > 3.0:
            apply_wta(ca1_neurons, k=len(targets))

    # --------------------------------------------------------
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ì‹œê°í™”)
    # --------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“Š HIPPOCAMPAL PROCESSING PIPELINE - VISUAL SUMMARY")
    print("=" * 70)
    
    # --------------------------------------------------------
    # 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
    # --------------------------------------------------------
    print("\nğŸ§  PROCESSING FLOW:")
    print("-" * 70)
    
    partial_input = [targets[0]]
    print("\nğŸ“¥ INPUT (Partial Cue):")
    input_viz = ""
    for i in range(N):
        if i in partial_input:
            input_viz += "ğŸ¯"
        else:
            input_viz += "Â·Â·"
    print(f"  {input_viz}")
    print(f"  Cue: N{partial_input[0]} (1/{len(targets)} = {100/len(targets):.0f}%)")
    
    print("\n  â¬‡ï¸  DG (Dentate Gyrus - Sparse Coding)")
    print("     â””â”€ High Leak (gL=0.1) filters noise")
    
    print("\n  â¬‡ï¸  CA3 (Pattern Completion)")
    print(f"     â”œâ”€ Selective Recurrent ({len(ca3_synapses)} synapses)")
    pattern_links = len([1 for i,j,_ in ca3_synapses if i in targets and j in targets])
    print(f"     â”œâ”€ Pattern Links: {pattern_links} (Q=15.0)")
    background_links = len(ca3_synapses) - pattern_links
    print(f"     â”œâ”€ Background: ~{background_links} (Q=3.0, 10%)")
    print(f"     â””â”€ WTA (k={len(targets)}) at t>2.0ms")
    
    print("\n  â¬‡ï¸  Schaffer Collaterals (CA3 â†’ CA1)")
    print("     â””â”€ Strong transmission (Q=25.0)")
    
    print("\n  â¬‡ï¸  CA1 (Output Filtering)")
    print("     â”œâ”€ Medium Leak (gL=0.08)")
    print(f"     â”œâ”€ Inhibition ({CA1_INHIB_RECALL})")
    print(f"     â””â”€ WTA (k={len(targets)}) at t>3.0ms")
    
    print("\n  â¬‡ï¸  Subiculum (Rate Decoder)")
    print("     â”œâ”€ Leaky Integrator (tau=2.0)")
    print("     â””â”€ Converts spikes â†’ activity level")
    
    print("\nğŸ“¤ OUTPUT (Cortical Readout):")
    
    # --------------------------------------------------------
    # 2. Subiculum Activity ì‹œê°í™”
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“ SUBICULUM ACTIVITY LEVELS")
    print("-" * 70)
    
    # ğŸ“ ì„ê³„ê°’: y > 2.0 â†’ "í™œì„±"ìœ¼ë¡œ íŒì •
    threshold = 2.0
    winners = [i for i in range(N) if sub_outputs[i] > threshold]
    
    # í™œì„±í™”ëœ ë‰´ëŸ°ë§Œ í‘œì‹œ
    active_found = False
    for i in range(N):
        val = sub_outputs[i]
        if val > 0.5:  # 0.5 ì´ìƒë§Œ í‘œì‹œ
            active_found = True
            bar_length = int(val * 2)
            bar = "â–ˆ" * bar_length
            
            # ìƒíƒœ í‘œì‹œ
            if i in targets:
                if val > threshold:
                    status = "ğŸ¯ TARGET âœ…"
                else:
                    status = "ğŸ¯ TARGET (weak)"
            else:
                if val > threshold:
                    status = "ğŸ”¥ NOISE âŒ"
                else:
                    status = "âšª Sub-threshold"
            
            print(f" N{i:2d}: {val:5.2f} | {bar:<20} {status}")
    
    if not active_found:
        print(" (No significant activity)")
    
    # --------------------------------------------------------
    # 3. íŒ¨í„´ ì‹œê°í™”
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“ˆ PATTERN ANALYSIS")
    print("-" * 70)
    
    print("\nğŸ¯ TARGET PATTERN:")
    target_viz = ""
    for i in range(N):
        if i in targets:
            target_viz += "â–ˆâ–ˆ"
        else:
            target_viz += "Â·Â·"
    print(f"  {target_viz}")
    print(f"  Expected: {targets}")
    
    print(f"\nğŸ“¤ SUBICULUM OUTPUT (>{threshold}):")
    output_viz = ""
    for i in range(N):
        if i in winners and i in targets:
            output_viz += "â–ˆâ–ˆ"  # ì„±ê³µ
        elif i in winners:
            output_viz += "ğŸ”¥"  # ë…¸ì´ì¦ˆ
        elif i in targets:
            output_viz += "â–“â–“"  # ëˆ„ë½
        else:
            output_viz += "Â·Â·"
    print(f"  {output_viz}")
    print(f"  Recalled: {winners}")
    
    # ë²”ë¡€
    print("\n  Legend:")
    print("    â–ˆâ–ˆ = Correct Target  |  ğŸ”¥ = Noise  |  â–“â–“ = Missed  |  Â·Â· = Silent")
    
    # --------------------------------------------------------
    # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“Š PERFORMANCE METRICS")
    print("-" * 70)
    
    # ğŸ“ ë©”íŠ¸ë¦­ ê³„ì‚°
    correct = set(winners) & set(targets)   # True positives
    missing = set(targets) - set(winners)   # False negatives
    noise = set(winners) - set(targets)     # False positives
    
    completion_rate = len(correct) / len(targets) * 100 if targets else 0
    noise_rate = len(noise) / N * 100
    
    # íŒ¨í„´ ì™„ì„±ë¥  ë°”
    bar_length = 30
    filled = int(bar_length * completion_rate / 100)
    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    print(f"Pattern Completion  : [{bar}] {completion_rate:.0f}%")
    print(f"                      ({len(correct)}/{len(targets)} targets)")
    
    # ë…¸ì´ì¦ˆ ë ˆë²¨ ë°”
    noise_filled = int(bar_length * min(noise_rate / 50, 1.0))
    noise_bar = "â–ˆ" * noise_filled + "â–‘" * (bar_length - noise_filled)
    print(f"Noise Level         : [{noise_bar}] {noise_rate:.1f}%")
    print(f"                      ({len(noise)}/{N} neurons)")
    
    # ğŸ“ SNR (Signal-to-Noise Ratio)
    if len(correct) > 0:
        snr = len(correct) / max(1, len(noise))
        print(f"Signal-to-Noise     : {snr:.2f} (higher is better)")
    
    # --------------------------------------------------------
    # 5. ìµœì¢… íŒì •
    # --------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ† FINAL VERDICT")
    print("=" * 70)
    
    if len(missing) == 0:
        print("\nâœ… PATTERN COMPLETION: SUCCESS!")
        if len(noise) == 0:
            print("ğŸ† PERFECT RECALL")
            print("   â””â”€ Zero noise. Flawless hippocampal processing!")
            print("   â””â”€ All targets recalled: ", correct)
        elif len(noise) <= 2:
            print("ğŸ¯ EXCELLENT RECALL")
            print(f"   â””â”€ Minor noise: {noise} (biologically realistic)")
            print(f"   â””â”€ All targets recalled: {correct}")
        else:
            print("âš ï¸  NOISY RECALL")
            print(f"   â””â”€ Noise detected: {noise}")
            print(f"   â””â”€ Targets recalled: {correct}")
    else:
        print("\nâŒ PATTERN COMPLETION: FAILED")
        print(f"   â””â”€ Missing targets: {missing}")
        print(f"   â””â”€ Recalled targets: {correct}")
        if len(noise) > 0:
            print(f"   â””â”€ Plus noise: {noise}")
    
    print("\nğŸ’¡ FULL PIPELINE VERIFIED:")
    print("   Input â†’ DG â†’ CA3 â†’ Schaffer â†’ CA1 â†’ Subiculum â†’ Cortex")
    print("=" * 70)


if __name__ == "__main__":
    run_hippo_complete()
