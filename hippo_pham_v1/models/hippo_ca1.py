"""
===================================================================================
HIPPO_CA1 â€” Full Hippocampal Pipeline (DG â†’ CA3 â†’ Schaffer â†’ CA1)
===================================================================================
ì§€ì€ì´: GNJz | ë°œí–‰: 2025.11.24

Complete Hippocampal Circuit with CA1 Output Layer

ğŸ“ êµ¬í˜„ëœ í•µì‹¬ ìˆ˜ì‹:

1ï¸âƒ£ Hodgkin-Huxley Neuron Dynamics (via v3_event.HHSomaQuick):
   C_m dV/dt = I_ext + I_syn - g_L(V-E_L) - g_NaÂ·mÂ³h(V-E_Na) - g_KÂ·nâ´(V-E_K)
   
   Gating variables:
   dm/dt = Î±_m(1-m) - Î²_mÂ·m
   dh/dt = Î±_h(1-h) - Î²_hÂ·h
   dn/dt = Î±_n(1-n) - Î²_nÂ·n

2ï¸âƒ£ Layer-Specific Leak Conductances:
   DG:  g_L = 0.1  (high leak â†’ strong noise filtering)
   CA3: g_L = 0.05 (standard â†’ pattern completion)
   CA1: g_L = 0.08 (medium â†’ output refinement)

3ï¸âƒ£ Short-Term Plasticity (STP) & Post-Tetanic Potentiation (PTP):
   On spike:  S â† min(1.0, S + 0.3),    PTP â† min(2.0, PTP + 0.05)
   Decay:     S â† max(0.0, S - 0.01),   PTP â† max(1.0, PTP - 0.001)

4ï¸âƒ£ Global Feedback Inhibition:
   I_inhib(t) = -N_active(t-1) Â· g_inhib
   
   Learning:  g_DG = 80.0,  g_CA3 = 20.0
   Recall:    g_DG = 150.0, g_CA3 = 60.0, g_CA1 = 35.0

5ï¸âƒ£ Winner-Take-All (WTA) Competition:
   Select top-k neurons by voltage V
   Suppress losers: V_loser â† -70 mV
   
   Timing: CA3 WTA at t > 2.0 ms, CA1 WTA at t > 3.0 ms

6ï¸âƒ£ Hippocampal Pathways:
   Mossy Fibers:        DG â†’ CA3  (1:1, Q=80.0, "detonator")
   Recurrent:           CA3 âŸ² CA3 (selective: pattern Q=15.0, bg Q=3.0)
   Schaffer Collateral: CA3 â†’ CA1 (1:1, Q=25.0, strong relay)

7ï¸âƒ£ Pattern Completion via CA3:
   Input:    Partial Cue (1/N neurons)
   CA3:      Recurrent amplification (pattern-selective connections)
   Schaffer: Strong transmission to CA1
   CA1:      Output filtering with WTA
   Output:   Complete Pattern (N/N neurons)

8ï¸âƒ£ Network Architecture:
   Learning:  Full Pattern â†’ DG â†’ CA3 (recurrent) â†’ Schaffer â†’ CA1
   Recall:    Partial Cue â†’ DG â†’ CA3 (completion) â†’ Schaffer â†’ CA1 â†’ Output

===================================================================================
"""

"""
===================================================================================
ğŸ“¦ Dependencies
===================================================================================

This module depends on `v3_event.py` which contains:
  - CONFIG (global Hodgkin-Huxley parameters)
  - HHSomaQuick (fast HH soma)
  - SynapseCore (synaptic event engine with delay queue)

If v3_event.py is not available, please check the project repository
or contact the author for the full package.

===================================================================================
"""

# Qquarts co Present
# ì§€ì€ì´ : GNJz 
# ë°œí–‰ 2025.11.24

import numpy as np
import random
import sys
from pathlib import Path

# âœ… Add parent directory to path for v3_event import
sys.path.insert(0, str(Path(__file__).parent.parent))

# âœ… í•µì‹¬ ì—”ì§„ ì„í¬íŠ¸
from v3_event import CONFIG, HHSomaQuick, SynapseCore

# ======================================================================
# 1. ë‰´ëŸ° í´ë˜ìŠ¤ ì •ì˜ (DG / CA3 / CA1)
# ======================================================================

class DGLightNeuron:
    """
    Dentate Gyrus Neuron â€” Sparse Pattern Encoder
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) High Leak Conductance:
       g_L = 0.1 (í‘œì¤€ì˜ 2ë°°)
       
       I_leak = g_L Â· (V - E_L)
       
       â†’ ë†’ì€ leak = ì•½í•œ ìê·¹ì€ í•„í„°ë§, ê°•í•œ ìê·¹ë§Œ í†µê³¼
    
    2) HH Dynamics:
       C_m dV/dt = I_ext + I_syn - g_L(V-E_L) - g_NaÂ·mÂ³h(V-E_Na) - g_KÂ·nâ´(V-E_K)
    
    3) STP/PTP:
       On spike:  S â† min(1.0, S + 0.3),    PTP â† min(2.0, PTP + 0.05)
       Decay:     S â† max(0.0, S - 0.01),   PTP â† max(1.0, PTP - 0.001)
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - DGëŠ” "pattern separator" â€” ìœ ì‚¬ ì…ë ¥ì„ êµ¬ë¶„
    - High leak â†’ sparse coding (ì ì€ ìˆ˜ì˜ ë‰´ëŸ°ë§Œ ë°œí™”)
    - "Gatekeeper" ì—­í•  â€” ë…¸ì´ì¦ˆ í•„í„°ë§
    """
    
    def __init__(self, name):
        self.name = name
        cfg = CONFIG["HH"].copy()
        cfg["gL"] = 0.1  # ğŸ“ High leak conductance (sparse filtering)
        self.soma = HHSomaQuick(cfg)
        self.S, self.PTP = 0.0, 1.0  # ğŸ“ STP/PTP state variables
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
            S (float): STP state
            PTP (float): PTP state
        """
        self.soma.step(dt, I_ext=I_ext)
        spike = self.soma.spiking()
        
        # ğŸ“ STP/PTP update
        if spike:
            self.S = min(1.0, self.S + 0.3)      # ğŸ“ S â† min(1.0, S + 0.3)
            self.PTP = min(2.0, self.PTP + 0.05)  # ğŸ“ PTP â† min(2.0, PTP + 0.05)
        else:
            self.S = max(0.0, self.S - 0.01)      # ğŸ“ S â† max(0.0, S - 0.01)
            self.PTP = max(1.0, self.PTP - 0.001) # ğŸ“ PTP â† max(1.0, PTP - 0.001)
            
        return spike, self.S, self.PTP


class CA3LightNeuron:
    """
    CA3 Neuron â€” Recurrent Pattern Completion Network
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) Standard Leak Conductance:
       g_L = 0.05 (í‘œì¤€ê°’)
       
       â†’ ì¤‘ê°„ ì •ë„ì˜ leak = íŒ¨í„´ ì™„ì„±ì— ìµœì í™”
    
    2) Recurrent Input:
       I_total = I_mossy + I_recurrent + I_inhib
       
       where I_recurrent = Î£_j Q_ij Â· S_j Â· PTP_j Â· K(t-t_spike)
    
    3) Pattern-Selective Connectivity:
       Q_ij = { 15.0  if i,j âˆˆ same pattern (strong attractor)
              {  3.0  if random background (10% probability)
              {  0.0  otherwise
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - CA3ëŠ” "auto-associative memory" â€” ë¶€ë¶„ ì…ë ¥ìœ¼ë¡œ ì „ì²´ íŒ¨í„´ ë³µì›
    - Recurrent connections â†’ attractor dynamics
    - Pattern-specific strong links â†’ ì„ íƒì  ì¦í­
    - Schaffer collateral â†’ CA1ìœ¼ë¡œ ì™„ì„±ëœ íŒ¨í„´ ì „ë‹¬
    """
    
    def __init__(self, name):
        self.name = name
        self.soma = HHSomaQuick(CONFIG["HH"])  # ğŸ“ Standard HH parameters
        self.S, self.PTP = 0.0, 1.0            # ğŸ“ STP/PTP state variables
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
            S (float): STP state
            PTP (float): PTP state
        """
        self.soma.step(dt, I_ext=I_ext)
        spike = self.soma.spiking()
        
        # ğŸ“ STP/PTP update
        if spike:
            self.S = min(1.0, self.S + 0.3)      # ğŸ“ S â† min(1.0, S + 0.3)
            self.PTP = min(2.0, self.PTP + 0.05)  # ğŸ“ PTP â† min(2.0, PTP + 0.05)
        else:
            self.S = max(0.0, self.S - 0.01)      # ğŸ“ S â† max(0.0, S - 0.01)
            self.PTP = max(1.0, self.PTP - 0.001) # ğŸ“ PTP â† max(1.0, PTP - 0.001)
            
        return spike, self.S, self.PTP


class CA1LightNeuron:
    """
    CA1 Neuron â€” Output Filter & Relay to Cortex
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) Medium Leak Conductance:
       g_L = 0.08 (ì¤‘ê°„ê°’)
       
       â†’ DGì™€ CA3 ì‚¬ì´ â€” ì ì ˆí•œ í•„í„°ë§ + ì „ë‹¬
    
    2) Schaffer Collateral Input:
       I_syn = Î£_j Q_j Â· S_j Â· PTP_j Â· K(t-t_spike)
       
       where j = CA3 neurons, Q = 25.0 (strong transmission)
    
    3) CA1 ì—­í• :
       - CA3ì˜ ì™„ì„±ëœ íŒ¨í„´ì„ "ì •ì œ"
       - WTAë¥¼ í†µí•œ sparse output
       - Subiculum/Entorhinal cortexë¡œ ì „ë‹¬
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - CA1ì€ CA3ì˜ ì¶œë ¥ì„ "í•„í„°ë§í•˜ì—¬" í”¼ì§ˆë¡œ ì „ë‹¬
    - Medium leak â†’ ì¤‘ê°„ ì •ë„ì˜ ì„ íƒì„±
    - Schaffer collateral â†’ CA3ì˜ ê°•ë ¥í•œ ì‹ í˜¸ë¥¼ ë°›ìŒ
    """
    
    def __init__(self, name):
        self.name = name
        cfg = CONFIG["HH"].copy()
        cfg["gL"] = 0.08  # ğŸ“ Medium leak conductance
        self.soma = HHSomaQuick(cfg)
        self.S, self.PTP = 0.0, 1.0  # ğŸ“ STP/PTP (not used in this model, but kept)
        
    def step(self, dt, I_ext=0.0):
        """
        ë‹¨ì¼ timestep ì‹¤í–‰
        
        Returns:
            spike (bool): ìŠ¤íŒŒì´í¬ ë°œìƒ ì—¬ë¶€
        """
        self.soma.step(dt, I_ext=I_ext)
        return self.soma.spiking()


# ======================================================================
# 1-1. WTA Helper (Winner-Take-All)
# ======================================================================

def apply_wta(neurons, k=5):
    """
    Winner-Take-All (WTA) â€” Sparse Competition
    
    ğŸ“ êµ¬í˜„ ìˆ˜ì‹:
    1) ì „ì•• ê¸°ì¤€ ì •ë ¬:
       V_sorted = sort([V_1, V_2, ..., V_N], descending)
    
    2) Top-k ì„ íƒ:
       Winners = {i | V_i âˆˆ top-k}
    
    3) Losers ì–µì œ:
       For i âˆˆ Losers:
         if V_i > -60 mV: V_i â† -70 mV (forced reset)
    
    ìƒë¬¼í•™ì  ì˜ë¯¸:
    - ì–µì œì„± ì¸í„°ë‰´ëŸ° (GABAergic interneurons)ì˜ í”¼ë“œë°± ì–µì œ ëª¨ì‚¬
    - Sparse representation ìœ ì§€
    - ë…¸ì´ì¦ˆ ì–µì œ
    - CA3ì™€ CA1ì—ì„œ ì‹œê°„ì°¨ë¥¼ ë‘ê³  ì ìš© (2.0ms, 3.0ms)
    
    Parameters:
        neurons: ë‰´ëŸ° ë¦¬ìŠ¤íŠ¸
        k: ìŠ¹ì ìˆ˜ (default: 5)
    """
    # ğŸ“ ìˆ˜ì‹: V_sorted = sort([V_1, ..., V_N], descending)
    voltages = [(i, n.soma.V) for i, n in enumerate(neurons)]
    voltages.sort(key=lambda x: x[1], reverse=True)
    
    # ğŸ“ ìˆ˜ì‹: Losers = {i | i âˆ‰ top-k}
    losers = [idx for idx, _ in voltages[k:]]
    
    # ğŸ“ ìˆ˜ì‹: V_loser â† -70 mV (forced reset)
    for idx in losers:
        if neurons[idx].soma.V > -60.0:  # Only reset if above threshold
            neurons[idx].soma.V = -70.0
            neurons[idx].soma.spike_flag = False
            neurons[idx].soma.mode = "rest"


# ======================================================================
# 2. í†µí•© ì‹œë®¬ë ˆì´ì…˜ (Full Hippocampus)
# ======================================================================

def run_hippo_full(N=20, dt=0.1):
    """
    Complete Hippocampal Pipeline Simulation
    
    ğŸ“ ì „ì²´ Pipeline:
    
    Phase 1 - Learning:
      Input â†’ DG â†’ CA3 (recurrent) â†’ Schaffer â†’ CA1
      
      ëª©ì : ì „ì²´ íŒ¨í„´ ì €ì¥ + Schaffer collateral ê°•í™”
      ì…ë ¥: Full pattern (3 neurons)
      ê²°ê³¼: CA3 recurrent + Schaffer synapses ê°•í™”
    
    Phase 2 - Reset:
      ëª¨ë“  ë‰´ëŸ° ë° ì‹œëƒ…ìŠ¤ ì´ˆê¸°í™”
      
      ëª©ì : Learningê³¼ Recall ë¶„ë¦¬
    
    Phase 3 - Recall:
      Partial Cue â†’ DG â†’ CA3 (completion) â†’ Schaffer â†’ CA1 â†’ Output
      
      ëª©ì : ë¶€ë¶„ ì…ë ¥ (1/3)ìœ¼ë¡œ ì „ì²´ íŒ¨í„´ ë³µì›
      CA3: Recurrent connectionsë¡œ íŒ¨í„´ ì™„ì„±
      Schaffer: ì™„ì„±ëœ íŒ¨í„´ì„ CA1ìœ¼ë¡œ ì „ë‹¬
      CA1: WTAë¡œ ë…¸ì´ì¦ˆ ì œê±° + ì¶œë ¥
    
    ğŸ“ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜:
    
    1) Layer-Specific Leak:
       g_DG = 0.1 (high)   â†’ Noise filtering
       g_CA3 = 0.05 (std)  â†’ Pattern completion
       g_CA1 = 0.08 (med)  â†’ Output refinement
    
    2) Global Inhibition (Feedback):
       I_inhib(t) = -N_active(t-1) Â· g_inhib
       
       â†’ ë§ì€ ë‰´ëŸ° ë°œí™” â†’ ê°•í•œ ì–µì œ â†’ Sparse coding ìœ ì§€
    
    3) Selective Recurrent (CA3):
       Q_ij = { 15.0  if i,j âˆˆ pattern (strong attractor)
              {  3.0  if background (weak)
       
       â†’ Pattern neuronsë§Œ ê°•í•˜ê²Œ ì—°ê²° â†’ ì„ íƒì  ì¦í­
    
    4) Schaffer Collateral:
       Q = 25.0 (CA3 â†’ CA1)
       
       â†’ ê°•ë ¥í•œ ì „ë‹¬ â€” CA3ì˜ ì™„ì„±ëœ íŒ¨í„´ì„ CA1ìœ¼ë¡œ
    
    5) Two-Stage WTA:
       CA3: t > 2.0 ms â†’ Top-3 ì„ íƒ
       CA1: t > 3.0 ms â†’ Top-3 ì„ íƒ
       
       â†’ ë‹¨ê³„ì  ë…¸ì´ì¦ˆ ì œê±°
    
    Parameters:
        N: ë‰´ëŸ° ìˆ˜ (default: 20)
        dt: Timestep (default: 0.1 ms)
    """
    
    # ğŸ² Reproducibility
    random.seed(42)
    np.random.seed(42)

    print(f"\nğŸ§  FULL HIPPOCAMPUS SIMULATION (Input -> DG -> CA3 -> CA1)")
    print("=" * 70)

    # --------------------------------------------------------
    # 1. ë‰´ëŸ° ìƒì„±
    # --------------------------------------------------------
    dg_neurons  = [DGLightNeuron(f"DG{i}")  for i in range(N)]
    ca3_neurons = [CA3LightNeuron(f"CA3{i}") for i in range(N)]
    ca1_neurons = [CA1LightNeuron(f"CA1{i}") for i in range(N)]

    # --------------------------------------------------------
    # 2. ì—°ê²° (Connectivity)
    # --------------------------------------------------------
    
    # ğŸ“ A) Perforant Path (Input â†’ DG): ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬
    # ìƒë¬¼í•™ì : Entorhinal cortex â†’ DG
    
    # ğŸ“ B) Mossy Fibers (DG â†’ CA3): 1:1 Detonator
    # ìƒë¬¼í•™ì : ê°•ë ¥í•œ "detonator" ì‹œëƒ…ìŠ¤
    mossy_fibers = []
    for i in range(N):
        syn = SynapseCore(pre_neuron=dg_neurons[i].soma, post_neuron=ca3_neurons[i].soma,
                          delay_ms=1.0, Q_max=80.0, tau_ms=2.0)  # ğŸ“ Strong detonator (Q=80.0)
        mossy_fibers.append(syn)

    # ğŸ“ C) CA3 Recurrent (CA3 âŸ² CA3): Selective Connectivity
    # Pattern-specific: ê°•í•œ ì—°ê²° (Q=15.0)
    # Background: ì•½í•œ ì—°ê²° (Q=3.0, 10% probability)
    ca3_synapses = []
    targets = [1, 7, 15]  # ğŸ“ Target pattern (3 neurons)
    
    for i in range(N):
        for j in range(N):
            if i == j: continue
            
            # ğŸ“ Pattern-selective connectivity
            is_pattern_link = (i in targets) and (j in targets)
            
            if is_pattern_link:
                # ğŸ“ Strong attractor: Q=15.0 (pattern neurons)
                syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca3_neurons[j].soma,
                                  delay_ms=1.5, Q_max=15.0, tau_ms=3.0)
                ca3_synapses.append((i, j, syn))
                
            elif random.random() < 0.10:
                # ğŸ“ Weak background: Q=3.0 (10% random)
                syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca3_neurons[j].soma,
                                  delay_ms=1.5, Q_max=3.0, tau_ms=3.0)
                ca3_synapses.append((i, j, syn))

    # ğŸ“ D) Schaffer Collaterals (CA3 â†’ CA1): 1:1 Strong Mapping
    # ìƒë¬¼í•™ì : CA3ì˜ ì£¼ìš” ì¶œë ¥ ê²½ë¡œ
    schaffer_collaterals = []
    for i in range(N):
        syn = SynapseCore(pre_neuron=ca3_neurons[i].soma, post_neuron=ca1_neurons[i].soma,
                          delay_ms=2.0, Q_max=25.0, tau_ms=3.0)  # ğŸ“ Strong transmission (Q=25.0)
        schaffer_collaterals.append(syn)

    print(f"Structure Built: DG({N}) -> CA3({N}) -> CA1({N})")

    # --------------------------------------------------------
    # PHASE 1: LEARNING (CA3 & Schaffer Potentiation)
    # --------------------------------------------------------
    print("\n=== PHASE 1: LEARNING (Target Pattern) ===")
    print(f"Target: {targets}")
    
    T_learn = 50.0  # Learning duration (ms)
    steps = int(T_learn / dt)
    
    # ğŸ“ Learning Inhibition Parameters
    DG_INHIB = 80.0   # ğŸ“ DG inhibition strength
    CA3_INHIB = 20.0  # ğŸ“ CA3 inhibition strength
    
    dg_last = 0   # ğŸ“ N_active(t-1) for DG
    ca3_last = 0  # ğŸ“ N_active(t-1) for CA3

    for k in range(steps):
        t = k * dt
        
        # ğŸ“ Input: Full pattern (t < 10 ms)
        dg_in = [0.0] * N
        if t < 10.0:
            for idx in targets:
                dg_in[idx] = 200.0  # ğŸ“ Strong input to target neurons
            
        # --------------------------------------------------------
        # DG Layer
        # --------------------------------------------------------
        dg_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_dg = -1.0 * dg_last * DG_INHIB
        
        for i in range(N):
            sp, S, PTP = dg_neurons[i].step(dt, dg_in[i] + I_dg)
            if sp:
                dg_now += 1
                # ğŸ“ Mossy fiber transmission
                mossy_fibers[i].on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
        
        dg_last = dg_now  # ğŸ“ Update N_active(t-1)

        # --------------------------------------------------------
        # Synapse Delivery
        # --------------------------------------------------------
        for syn in mossy_fibers:
            syn.deliver(t)
        for _, _, syn in ca3_synapses:
            syn.deliver(t)

        # --------------------------------------------------------
        # CA3 Layer (Recurrent)
        # --------------------------------------------------------
        ca3_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_ca3 = -1.0 * ca3_last * CA3_INHIB
        
        for i in range(N):
            I_syn = ca3_neurons[i].soma.get_total_synaptic_current()
            sp, S, PTP = ca3_neurons[i].step(dt, I_syn + I_ca3)
            
            if sp:
                ca3_now += 1
                # ğŸ“ Recurrent transmission
                for pre, post, syn in ca3_synapses:
                    if pre == i:
                        syn.on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
                
                # ğŸ“ Schaffer collateral transmission (ì¤‘ìš”!)
                # CA3 â†’ CA1 ê²½ë¡œ ê°•í™”
                schaffer_collaterals[i].on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
        
        ca3_last = ca3_now  # ğŸ“ Update N_active(t-1)

    print("âœ… Learning Complete (CA3 & Schaffer Potentiated).")

    # --------------------------------------------------------
    # PHASE 2: RESET (System Cooldown)
    # --------------------------------------------------------
    print("\n=== PHASE 2: RESET ===")
    
    # ğŸ“ Cooldown: ëª¨ë“  transient dynamics ì†Œë©¸
    for _ in range(500):
        for n in dg_neurons + ca3_neurons + ca1_neurons:
            n.step(dt, 0)
        for s in mossy_fibers:
            s.deliver(0)
        for _, _, s in ca3_synapses:
            s.deliver(0)
        for s in schaffer_collaterals:
            s.deliver(0)

    # ğŸ“ Force Reset: ëª¨ë“  state variables ì´ˆê¸°í™”
    all_neurons = dg_neurons + ca3_neurons + ca1_neurons
    for n in all_neurons:
        n.soma.V = -70.0
        n.soma.m, n.soma.h, n.soma.n = 0.05, 0.6, 0.32
        n.soma.spike_flag = False
        n.soma.I_syn_total = 0.0
        n.soma.active_remaining = 0.0
        n.soma.mode = "rest"
    
    # ğŸ“ Synapse Reset (Spike Queue Clear)
    all_synapses = mossy_fibers + [s for _, _, s in ca3_synapses] + schaffer_collaterals
    for s in all_synapses:
        s.spikes = []
        s.I_syn = 0.0
        
    dg_last = 0
    ca3_last = 0
    print("Reset Done.")

    # --------------------------------------------------------
    # PHASE 3: RECALL (Partial Cue â†’ Pattern Completion â†’ CA1 Output)
    # --------------------------------------------------------
    print("\n=== PHASE 3: RECALL (Input: N1 only) ===")
    partial_input = [1]  # ğŸ“ Partial cue (1/3 of pattern)
    print(f"Input: {partial_input} (Missing {list(set(targets)-set(partial_input))})")
    
    T_test = 50.0  # Recall duration (ms)
    steps = int(T_test / dt)
    
    # ğŸ“ Recall Inhibition (stronger than learning)
    DG_INHIB_RECALL = 150.0   # ğŸ“ Strong DG inhibition
    CA3_INHIB_RECALL = 60.0   # ğŸ“ Strong CA3 inhibition
    CA1_INHIB_RECALL = 35.0   # ğŸ“ CA1 noise filter

    ca3_log = set()  # ğŸ“ CA3 í™œì„± ë‰´ëŸ° ê¸°ë¡
    ca1_log = set()  # ğŸ“ CA1 í™œì„± ë‰´ëŸ° ê¸°ë¡

    for k in range(steps):
        t = k * dt
        
        # --------------------------------------------------------
        # 1. DG (Input Filtering)
        # --------------------------------------------------------
        dg_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_dg = -1.0 * dg_last * DG_INHIB_RECALL
        
        for i in range(N):
            # ğŸ“ Partial Cue: Only first target neuron (t < 10 ms)
            I_in = 200.0 if (i in partial_input and t < 10.0) else 0.0
            sp, S, PTP = dg_neurons[i].step(dt, I_in + I_dg)
            
            if sp:
                dg_now += 1
                mossy_fibers[i].on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
        
        dg_last = dg_now

        # --------------------------------------------------------
        # 2. Synapse Delivery
        # --------------------------------------------------------
        for syn in mossy_fibers:
            syn.deliver(t)
        for _, _, syn in ca3_synapses:
            syn.deliver(t)
        for syn in schaffer_collaterals:
            syn.deliver(t)

        # --------------------------------------------------------
        # 3. CA3 (Pattern Completion with WTA)
        # --------------------------------------------------------
        ca3_now = 0
        # ğŸ“ Global inhibition: I_inhib = -N_active(t-1) Â· g_inhib
        I_ca3 = -1.0 * ca3_last * CA3_INHIB_RECALL
        
        for i in range(N):
            I_syn = ca3_neurons[i].soma.get_total_synaptic_current()
            sp, S, PTP = ca3_neurons[i].step(dt, I_syn + I_ca3)
            
            if sp:
                ca3_now += 1
                ca3_log.add(i)  # ğŸ“ Record CA3 activity
                
                # ğŸ“ Recurrent amplification
                for pre, post, syn in ca3_synapses:
                    if pre == i:
                        syn.on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
                
                # ğŸ“ Schaffer collateral transmission (PTP ì ìš©!)
                schaffer_collaterals[i].on_pre_spike(t, S, PTP)  # ğŸ“ Uses default: ATP=100.0, dphi=0.0
        
        ca3_last = ca3_now
        
        # ğŸ“ WTA: CA3 sparse competition (after 2.0 ms)
        if t > 2.0:
            apply_wta(ca3_neurons, k=3)  # Top-3 neurons

        # --------------------------------------------------------
        # 4. CA1 (Final Output / Decoding with WTA)
        # --------------------------------------------------------
        I_ca1 = -CA1_INHIB_RECALL  # ğŸ“ Constant inhibition
        
        for i in range(N):
            I_syn = ca1_neurons[i].soma.get_total_synaptic_current()
            sp = ca1_neurons[i].step(dt, I_syn + I_ca1)
            
            if sp:
                ca1_log.add(i)  # ğŸ“ Record CA1 activity
        
        # ğŸ“ WTA: CA1 sparse competition (after 3.0 ms)
        if t > 3.0:
            apply_wta(ca1_neurons, k=3)  # Top-3 neurons

    # --------------------------------------------------------
    # ê²°ê³¼ ë¶„ì„ (ì‹œê°í™”)
    # --------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ“Š HIPPOCAMPAL MEMORY RETRIEVAL - RESULT ANALYSIS")
    print("=" * 70)
    
    # ğŸ“ ë©”íŠ¸ë¦­ ê³„ì‚°
    missing = set(targets) - ca1_log   # False negatives
    noise = ca1_log - set(targets)     # False positives
    
    # --------------------------------------------------------
    # 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
    # --------------------------------------------------------
    print("\nğŸ§  PROCESSING FLOW:")
    print("-" * 70)
    
    print("\nğŸ“¥ INPUT (Partial Cue):")
    input_viz = ""
    for i in range(N):
        if i in partial_input:
            input_viz += "ğŸ¯"
        else:
            input_viz += "Â·Â·"
    print(f"  {input_viz}")
    print(f"  Cue: {partial_input} (1/{len(targets)} = 33%)")
    
    print("\n  â¬‡ï¸  DG (Dentate Gyrus - Sparse Coding)")
    print("     â””â”€ High Leak (gL=0.1) filters noise")
    
    print("\n  â¬‡ï¸  CA3 (Pattern Completion)")
    print(f"     â”œâ”€ Selective Recurrent ({len(ca3_synapses)} synapses)")
    pattern_links = len([1 for i, j, _ in ca3_synapses if i in targets and j in targets])
    print(f"     â”œâ”€ Pattern Links: {pattern_links} (Q=15.0)")
    background_links = len(ca3_synapses) - pattern_links
    print(f"     â”œâ”€ Background: ~{background_links} (Q=3.0, 10%)")
    print("     â””â”€ WTA (k=3) at t>2.0ms")
    
    print("\nğŸ§  CA3 OUTPUT:")
    ca3_viz = ""
    for i in range(N):
        if i in targets and i in ca3_log:
            ca3_viz += "â–ˆâ–ˆ"
        elif i in targets and i not in ca3_log:
            ca3_viz += "â–“â–“"
        elif i in (ca3_log - set(targets)):
            ca3_viz += "ğŸ”¥"
        else:
            ca3_viz += "Â·Â·"
    print(f"  {ca3_viz}")
    print(f"  Neurons: {sorted(list(ca3_log))}")
    
    print("\n  â¬‡ï¸  Schaffer Collaterals (CA3 â†’ CA1)")
    print("     â””â”€ Strong transmission (Q=25.0)")
    
    print("\n  â¬‡ï¸  CA1 (Output Filtering)")
    print("     â”œâ”€ Medium Leak (gL=0.08)")
    print(f"     â”œâ”€ Inhibition ({CA1_INHIB_RECALL})")
    print("     â””â”€ WTA (k=3) at t>3.0ms")
    
    print("\nğŸ“ CA1 OUTPUT (Final):")
    ca1_viz = ""
    for i in range(N):
        if i in targets and i in ca1_log:
            ca1_viz += "â–ˆâ–ˆ"
        elif i in targets and i not in ca1_log:
            ca1_viz += "â–“â–“"
        elif i in (ca1_log - set(targets)):
            ca1_viz += "ğŸ”¥"
        else:
            ca1_viz += "Â·Â·"
    print(f"  {ca1_viz}")
    print(f"  Neurons: {sorted(list(ca1_log))}")
    
    # ë²”ë¡€
    print("\n  Legend:")
    print("    ğŸ¯ = Input Cue  |  â–ˆâ–ˆ = Target Recalled  |  â–“â–“ = Target Missed")
    print("    ğŸ”¥ = Noise      |  Â·Â· = Silent")
    
    # --------------------------------------------------------
    # 2. íŒ¨í„´ ë¹„êµ
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“ˆ PATTERN ANALYSIS")
    print("-" * 70)
    
    print("\nğŸ¯ TARGET PATTERN:")
    target_viz = ""
    for i in range(N):
        if i in targets:
            target_viz += "â–ˆâ–ˆ"
        else:
            target_viz += "Â·Â·"
    print(f"  {target_viz}")
    print(f"  Expected: {targets}")
    
    print("\nğŸ“¤ CA1 OUTPUT:")
    output_viz = ""
    for i in range(N):
        if i in ca1_log and i in targets:
            output_viz += "â–ˆâ–ˆ"
        elif i in ca1_log:
            output_viz += "ğŸ”¥"
        elif i in targets:
            output_viz += "â–“â–“"
        else:
            output_viz += "Â·Â·"
    print(f"  {output_viz}")
    print(f"  Recalled: {sorted(list(ca1_log))}")
    
    # --------------------------------------------------------
    # 3. ìƒì„¸ ë¶„ì„
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“‹ DETAILED ANALYSIS")
    print("-" * 70)
    
    correct = set(ca1_log) & set(targets)
    
    print(f"Target Pattern      : {targets}")
    print(f"Input (Partial Cue) : {partial_input} â†’ Missing: {sorted(list(set(targets) - set(partial_input)))}")
    print(f"CA3 Output          : {sorted(list(ca3_log))}")
    print(f"CA1 Output          : {sorted(list(ca1_log))}")
    
    print("\nâœ“ Completed Targets : ", end="")
    if correct:
        print(f"{sorted(list(correct))} âœ…")
    else:
        print("None âŒ")
    
    print("âœ— Missing Targets   : ", end="")
    if missing:
        print(f"{sorted(list(missing))} âŒ")
    else:
        print("None âœ…")
    
    print("âš  Noise Neurons     : ", end="")
    if noise:
        print(f"{sorted(list(noise))} âš ï¸")
    else:
        print("None ğŸ†")
    
    # --------------------------------------------------------
    # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­
    # --------------------------------------------------------
    print("\n" + "-" * 70)
    print("ğŸ“Š PERFORMANCE METRICS")
    print("-" * 70)
    
    completion_rate = len(correct) / len(targets) * 100 if targets else 0
    noise_rate = len(noise) / N * 100
    
    # íŒ¨í„´ ì™„ì„±ë¥  ë°”
    bar_length = 30
    filled = int(bar_length * completion_rate / 100)
    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    print(f"Pattern Completion  : [{bar}] {completion_rate:.0f}%")
    print(f"                      ({len(correct)}/{len(targets)} targets)")
    
    # ë…¸ì´ì¦ˆ ë ˆë²¨ ë°”
    noise_filled = int(bar_length * min(noise_rate / 50, 1.0))
    noise_bar = "â–ˆ" * noise_filled + "â–‘" * (bar_length - noise_filled)
    print(f"Noise Level         : [{noise_bar}] {noise_rate:.1f}%")
    print(f"                      ({len(noise)}/{N} neurons)")
    
    # ğŸ“ SNR (Signal-to-Noise Ratio)
    if len(correct) > 0:
        snr = len(correct) / max(1, len(noise))
        print(f"Signal-to-Noise     : {snr:.2f} (higher is better)")
    
    # --------------------------------------------------------
    # 5. ìµœì¢… íŒì •
    # --------------------------------------------------------
    print("\n" + "=" * 70)
    print("ğŸ† FINAL VERDICT")
    print("=" * 70)
    
    if len(missing) == 0:
        print("\nâœ… PATTERN COMPLETION: SUCCESS!")
        if len(noise) == 0:
            print("ğŸ† PERFECT RECALL")
            print("   â””â”€ Zero noise. Flawless hippocampal processing!")
            print(f"   â””â”€ All targets recalled: {sorted(list(correct))}")
        elif len(noise) == 1:
            print("ğŸ¯ EXCELLENT RECALL")
            print(f"   â””â”€ Minimal noise: {sorted(list(noise))} (biologically ideal!)")
            print(f"   â””â”€ All targets recalled: {sorted(list(correct))}")
        elif len(noise) <= 2:
            print("âœ¨ VERY GOOD RECALL")
            print(f"   â””â”€ Minor noise: {sorted(list(noise))} (biologically realistic)")
            print(f"   â””â”€ All targets recalled: {sorted(list(correct))}")
        else:
            print("âš ï¸  NOISY RECALL")
            print(f"   â””â”€ Noise detected: {sorted(list(noise))}")
            print(f"   â””â”€ Targets recalled: {sorted(list(correct))}")
    else:
        print("\nâŒ PATTERN COMPLETION: FAILED")
        print(f"   â””â”€ Missing targets: {sorted(list(missing))}")
        print(f"   â””â”€ Recalled targets: {sorted(list(correct))}")
        if len(noise) > 0:
            print(f"   â””â”€ Plus noise: {sorted(list(noise))}")
    
    print("\nğŸ’¡ FULL PIPELINE VERIFIED:")
    print("   Input â†’ DG â†’ CA3 (Selective + WTA) â†’ Schaffer â†’ CA1 (WTA) â†’ Output")
    print("=" * 70)


if __name__ == "__main__":
    run_hippo_full()
